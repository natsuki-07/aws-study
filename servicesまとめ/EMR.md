# Amazon EMR  
業界をリードするビックデータのクラウドプラットフォームでApache Spark、Apache Hive、Apache HBase、Apache Flink、Apache Hudi、Presto などのオープンソースツールを活用して膨大な量のデータを処理できる。Amazon EMRでは、キャパシティのプロビジョニングやクラスターの調整などの時間のかかるタスクを自動化することでビックデータ環境の設定、運用、スケーリングが簡単に行える。EMRは従来のオンプレミスソリューションの半分以下のコスト、標準的なApacheSparkの3倍以上の速さで、ペタバイト規模の分析を実行できる  

## アーキテクチャ  
EMRはマスターノード、コアノード、タスクノードという3種類のノードで構成される
- マスターノードはマスターの役割を果たし、コアノード、タスクノードにジョブを振り分ける。マスターノードは1台のみ存在し、フェイルオーバーができない。  
- コアノードとタスクノードはどちらも実際のジョブを実行する。両者の違いは、コアノードはデータを保存する領域であるHDFSを持ち、タスクノードはHDFSを持たない。そのためタスクノードはコアノードに比べて柔軟に増減ができる。ただしコアノードなしでタスクノードのみの構成にすることはできない。  
  
  
## 分散基盤としてのEMR  
1つの機能として、分散処理基盤がある。これには分散処理に必要なEC2の調達・廃棄などのリソースの調整機能と、S3を分散処理に扱いやすいストレージとして扱う機能(EMRFS)がある。リソースの調整機能として重要になるのは伸縮自在性とコスト。伸縮自在性は処理するEC2インスタンスを解析開始時に調達し、必要に応じて増減させる機能。  
コストの観点ではEMRには分析費用を小さくするための機能がある。スポットインスタンスと相性が良い。  
   
   
分散処理の機能の構成要素の1つとして、ジョブの分割と管理がある。ジョブの分割は全体の処理を小さな単位のジョブとして分割することで、ジョブの管理は分割したジョブを分散処理基盤内のインスタンスに振り分けその成否を管理する機能。   
  
  
## ETLツール  
ETLはExtract Transform Loadの略でデータソースからのデータの抽出・変換・投入の役割を果たす。  
  
### Kinesis  
AWSが提供するストリーミング処理プラットフォーム。Kinesisにはセンサーやログなどデータをリアルタイム/純リアルタイムで処理するData StreamsとData Firehose、動画を処理するVideo Streams、収集したデータを可視化・分析するData Analyticsの4つの機能がある。  
  
## Data Pipeline 
データ処理やデータ移動を支援するサービス。Data Pipeline でパイプラインを設定するとオンプレミスやAWS上の特定の場所に定期的にアクセスし、必要に応じてデータを変換し、S3、RDS、DynamoDBなどのAWS各種サービスに転送する。  
  
## Glue  
データレイクやデータウェアハウスとセットで使われることが多いサーバーレス型のETLツール。ビッグデータの解析などに使われることが多くS3のデータを管理してRedshiftなどに変換して格納するといった用途によく利用される。  
データ管理機能としては、データソースのデータを探索するクローラー機能と、それをメタデータとして管理するデータカタログの機能がある。  
実際のデータ変換処理は、変換エンジンで行われる。Glueではこの処理をジョブという単位で管理する。変換処理はPythonやSparkによって自分で実装できる。ビッグデータのETLツールとしてはLambdaやGlueがよくつかわれる  
  
  
# その他の分析サービス  
## Amazon Athena  
S3内のデータを直接分析できるようにする対話型のクエリサービス。所定の形式で格納されたS3のデータに対して、標準SQLでデータの操作ができる。  

## Amazon QuickSight  
データの可視化ツール。QuickSightを利用することで簡単にダッシュボードを作成することができる。作成したダッシュボードはブラウザ経由で閲覧可能で、アプリケーション、ポータル、Webサイトに埋め込むことができる。ビッグデータ分析などのビジネス的な解析の可視化にはQuickSightを利用する。