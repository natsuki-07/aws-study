# 開発
AWSの各サービスへのリクエストはマネジメントコンソールで操作しても、AWS CLIで操作しても。SDKからリクエストを実行してもAWSのAPIに対してリクエストが実行される  
  
AWS SDKやCDKを使用すると、設定されている認証情報を使って、署名などAWSのAPIリクエストに必要な情報が自動生成される。認証情報の優先順位は以下のようになる  
  
1. コードのオプションやパラメータで指定されたアクセスキー情報
2. 環境変数
3. .aws/credentialsファイル
4. EC2のIAMロール
  
## ストレージ
Elastic Block Store(EBS)ボリュームは、EC2インスタンスにアタッチして使用する。アタッチするEC2インスタンスと同じアベイラビリティソーンに作成する。  
  
Elastic File System(EFS)は、EC2インスタンスからマウントして使用する。EFSファイルシステムは、複数のアベイラビリティーゾーンにマウントポイントを作成することができる。EBSボリュームはOSやソフトウェアなどを起動するために使用し、増減するデータの保存先として使う。ファイルシステムをマウントして使用できるので、オンプレミスで使用しているモノリシックなアプリケーションをカスタマイズしなくても、データの保存先を変更するだけでAWSに移行できる。
  
Simple Storage Service(S3)は、ユーザーがシンプルに使うことができる、インターネット対応のストレージサービス。リージョンを選択して、オブジェクトの入れ物であるバケットを作成することで、簡単に使用できる。  
  
### S3の主なユースケース
- データレイク
あらゆる場所から、あらゆる形式のデータをそのままの形で保存して、集計や機械学習などの様々な分析用途で使用するための保管場所のことをデータレイクと呼ぶ。その保管場所として最適なサービスがS3。  
S3ではデータの作成通知イベントによってリアルタイムなデータの加工・分析を行うこともできる。  
  
AWS Glue・・・データの加工、データカタログの作成  
  
AWS EMR・・・Apache Hadoop/Sparkなどの分析やデータ加工処理用のOSSをマネージドサービスとして提供  
  
Amazon Redshift・・・マネージドデータウェアハウス。S3からデータをロードして使うこともできるし、Redshift Spectrumを使用してS3のデータを直接分析することもできる。  
  
Amazon SageMaker・・・S3に蓄積したデータを使って、継続的に推論モデルを作成することができる  
  
Amazon Athena・・・S3に蓄積したデータについて、直接SQLクエリでの分析ができる。複数ファイルをまとめてデータベースのように扱うことができる  
  
Amazon QuickSight・・・様々なデータソースのデータをグラフなどで可視化できるBI(ビジネスインテリジェンス)サービス  
  
AWS Lake Formation・・・S3とGlueやAthenaを使用したデータレイクを素早く構築できる  
  
  
- S3 Select
サイズの大きい1つのオブジェクトデータをクライアントにダウンロードして分析していると、ダウンロードするための時間とデータ転送コストが発生する。アプリケーションが使いたいデータは、そのデータの一部分の場合もある。そういったときはS3 Selectを実行することによりSQL文で抽出したデータだけをダウンロードすることができる。こうしてデータ転送時間とデータ転送コストを低減することができる。  
  
- バックアップとアーカイブ
データのバックアップ先やアーカイブ先として使用されるケースもよくある。  
  
#### バージョニングとオブジェクトロック
例えばアプリケーションのログデータを1年間保存しておかなければならない要件があったとする。そして、そのログデータは誰も削除や上書きをしてはいけない要件があったとする。  
  
バージョニングはバケット単位で有効にできる。バージョニングが無効なS3バケットでは、同じオブジェクトキーでPutObjectすると、オブジェクトが上書きされて上書き前のオブジェクトはなくなる。有効にしたS3バケットでは上書き前のオブジェクトも上書き後のオブジェクトもそれぞれバージョンIDが設定されて、バケットに残っていく。
  
GetObjectなどオブジェクトに対してアクセスする場合は、最新バージョンのオブジェクトにアクセスできる。DeleteObjectした場合は、削除前のオブジェクトは残したままオブジェクトの削除マーカーができる。バージョンを指定する場合は`GetObjectVersion`, `DeleteObjectVersion`アクションへの許可が必要。
  
誰も削除や上書きをしてはいけないという厳しい要件があったとする。その場合はオブジェクトロックを有効にする。オブジェクトロックはバージョンIDを指定した操作なのでバージョニングが有効である必要がある。オブジェクトロックには、コンプライアンスモードとガバナンスモードがあり、コンプライアンスモードでオブジェクトロックを有効にして保持期間を設定したオブジェクトはすべてのユーザーからの削除を拒否する。
  
AWS Storage Gatewayではオンプレミスに仮想マシンをデプロイして、保存したデータが自動的にS3を使用sるようにする。オンプレミスのアプリケーションから等価的にS3を使用することができる。  
  
ファイルゲートウェイ・・・NFS/SMBプロトコルで接続  
  
ボリュームゲートウェイ・・・iSCSIプロトコルで接続
  
テープゲートウェイ・・・仮想テープライブラリとして接続
  
- 静的ウェブサイトとコンテンツの配信  
  
S3バケットに性的なファイルを配置して、適切なアクセス権を設定すればHTTP/HTTPSプロトコルでアクセスできる。  
  
CloudFront + S3・・・S3バケットはユーザーがリージョンを選択して作成する。静的なコンテンツを世界中に展開する際は、リクエスト元のクライアントからの距離が遠くなればなるほど高いレイテンシーが発生する。
そこでCloudFrontを使うことで世界中200か所以上のエッジロケーションを使用してキャッシュコンテンツを配信していくことができる。S3バケットはメインとなるリージョンに配置してCloudFrontを設定することで、ユーザーから見て最もレイテンシーの低いエッジロケーションにリクエストが送信され、そのエッジローケーションにキャッシュがなければS3バケットへのリクエストが実行される。  
  
- アプリケーションコンテンツの保存  
  
頻繁に更新するオブジェクトでなければ、S3バケットに保存することが効率的。S3バケットへのオブジェクトのアップロード、ダウンロード操作はSDKを使用して開発する。  
  
PutObjectアクションを実行するとアップロードができる。1つのサイズが大きいオブジェクトをアップロードするときに、効率化を図る方法がマルチアップロードAPI。1つのオブジェクトを複数のパーツに分散して並列アップロードをする。各パーツのアップロードが完了すると、1つのオブジェクトに結合される。  
  
copyオペレーションを実行すると、アップロード済みの既存オブジェクトを指定したバケットやキーでコピーすることができる。既存オブジェクトのメタデータを編集することはできないので、既存オブジェクトのメタデータを編集する必要がある場合はcopyオペレーションを実行する。  
  
GetObjectアクションを実行することで、オブジェクトを取得できる。各SDKに、GetObjectを実行するためのメソッドが用意されている。オブジェクトの一覧情報の取得はListObjectsアクションで行う。リクエストパラメータにプレフィックスを指定して、特定のオブジェクトのリスト情報を取得することができる。
  
DeleteObjectリクエストではオブジェクトの削除ができる。バージョニングが無効か有効化で動作が変わってくる。無効なバケットでは、オブジェクトキーを指定してオブジェクトを完全に削除する。バージョニングが有効なバケットでは、オブジェクトキーを指定してDeleteObjectアクションを実行すると削除マーカーが作成される。最新バージョンに対する削除マーカーが作成されているオブジェクトを取得しようとすると、`404NotFound`エラーが返される。オブジェクトキーとバージョンIDを指定してDeleteObjectVersionアクションを実行することで、オブジェクトの完全削除ができる。  
  
アクセスコントロールリスト・・・静的Webサイトのように、S3バケットに格納したオブジェクトをパブリックに公開する場合は、オブジェクトのアクセスコントロールリストを使用する。  
  
バケットポリシー・・・より詳細なアクセス権限を設定したい場合は、バケットポリシーを使用する。
  
署名付きURL・・・S3バケットに保存したオブジェクトを特定の人だけにダウンとーろしてほしい場合は、署名付きURLが利用できる。  
  
CORS・・・S3ではCORSの設定が可能。CORSにより、他の許可されたドメインからのリクエストを許可することができる。  
  
暗号化・・・S3オブジェクトの暗号化は、サーバーサイド暗号化、クライアント暗号化といった要件に応じた選択肢がある。  
  
整合性・・・S3オブジェクトのアップロードの前後で整合性を確認する場合は、MD5チェックサム値を使用する。  
  
トラブルシューティング：  
  - InternalError・・・S3内でエラーが発生しているので再試行
  - NoSuchBucket・・・バケットが存在しない。
  - BucketAlreadyExists・・・新規作成時に既にバケットが存在している
  - InvalidBucketName・・・新規作成時に発生し、バケット名が無効。


## データベース
### RDS
非同期、読み取り専用のリードレプリカは5つまで作成することができ、他のリージョンにも作成することができる(クロスリージョンリードレプリカ)。バックアップのスナップショットはAWSがリージョンを使って安全に保管するので、アベイラビリティーゾーン単位の障害が発生してもスナップショットにはアクセスできる。スナップショットのほかのリージョンへコピーできるので、災害対策ができる(クロスリージョンコピー)    
  
Amazon AuroraはAWSがユーザーのニーズを満たすために開発したデータベースで、性能としてはMySQLの5倍のスループット、PostgreSQLの3倍のスループットがある。コンピューティング層とストレージ層を分割して、ストレージは３つのアベイラビリティーゾーンに6つのレプリケートを作成し、ストレージは10GBごとに最大128TBまで自動拡張する。  
  
アプリケーションからはRDSと同様、マスターに対して接続するが、フェイルオーバーするのはスタンバイではなく読み取り可能なリードレプリカ。リードレプリカは最大15まで作成できる。グローバルデータベース機能で、他リージョンに秒未満の最小限の遅延で同期されるレプリカを作成でき、1分未満でセカンダリリージョンにフェイルオーバーできるので災害対策に有用。
  
キャパシティタイプにプロビジョニングタイプとサーバレスタイプがある。プロビジョニングタイプは性能をインスタンスクラスで指定して時間課金が発生する。リードレプリカやぐろーばデータベースはプロビジョニングタイプ。サーバレスタイプは、Auroraキャパシティユニット(ACU)に応じて時間課金が発生する。1ACUあたり2GBのメモリと、それに応じたCPU性能が提供される。最小ACUと最大ACU間で負荷に応じて自動的にスケーリングする。オプションでアイドル状態が続いたときにコンピューティング性能を自動停止し、ACUに対する時間課金を停止することができる。
  
### ElasticCache
ElasticCacheのキャッシュノードは、VPCのサブネットをグループにしたサブネットグループを指定して起動することで、複数のアベイラビリティゾーンでノードクラスターとして起動できる。インメモリデータストアにおいてキーバリュー型でデータを保管して、クエリに対して素早くレスポンスを返す。  
  
ElasticCacheはMemcachedとRedisを提供する。MemcachedとRedisの共通の特徴は以下のようにある
- ミリ秒レイテンシー(応答時間)・・・メモリ内にデータを格納するインメモリデータストア  
- 複数ノードへのデータ分散によるスケーラビリティ・・・サブネットグループに配置することで、複数のアベイラビリティーゾーンにノードを配置できる。ノードの数はリクエストが増加した際に増やせるので、スケーラビリティを確保する  
  
- 様々なプログラミング言語をサポート
  
2つの大きな違いとしてはMemcachedがマルチスレッド、RedisがレプリケーションやPub/Subをサポートしている点。Memcachedはマルチスレッドをサポートしているので、水平的なスケールアウトをしやすいメリットがある。Redisはアベイラビリティーゾーンをまたいでリードレプリカを作成し、障害児にフェイルオーバーできるので、耐障害性のメリットがある。永続的にデータを保存する要件で使用されることも多くあり、様々な機能に対応している。  
  
### DynamoDB
パーテションを分散させることで、水平スケーリングを可能とするため、多くのリクエストが発生するアプリケーションに非常に適している。  
  
データを一意として扱うために、作成時にプライマリキーを決定しておく必要があり、2パターンある。1つはパーテションキーのみでプライマリキーにできるケース。もう1つはパーテションキーとソートキーの2つでプライマリキーとするケース  
  
#### 請求モード
書き込み、読み込みは2つの請求モードから選択できる。請求モードはテーブル作成後にも変更できる
  
- オンデマンドキャパシティモード  
読み込み回数とサイズ、書き込み回数とサイズに応じて請求が発生する。後述する結果整合性での読み込みに対して、強力な整合性での読み込みは倍のコストが発生する。急激なスパイクリクエストにも対応できるので、リクエスト数が予測できないケースに向いている。
  
- プロビジョニング済みキャパシティモード  
読み込みキャパシティユニットと書き込みキャパシティユニットをプロビジョニングするモード。読み込みキャパシティユニットはRead Capacity Unitで略してRCU、書き込みキャパシティユニットはWrite Capacity Unitで略してWCUと表記されることもある。  
  
1つの書き込みキャパシティユニットでできることは最大1KBの項目を1秒間に1回書き込むこと。1つの読み込みキャパシティユニットでできることは最大4KBの項目を1秒間に2回結果整合性で読み込むか、1秒間に1回強力な結果整合性で読み込むかである。  
  
結果整合性は、項目を書き込んだ直後、更新した直後、削除した直後に別プロセスから読み込むとまだ書き込まれていない、更新されていない、削除されていないという未反映の項目を読み込む可能性がある整合性。強力な結果整合性は更新された項目をリアルタイムで読み込む。  
  
読み込みキャパシティユニット、書き込みキャパシティユニットは最小値・最大値を決めてオーとスケーリングをすることも可能で、オーとスケーリングはCloudWatchアラームと連携する。ただ急激なスパイクリクエストには間に合わない場合もある。  

#### セカンダリインデックス
パーテションキーとソートキーを設定しているテーブルでは、パーテションで絞り込んでソートキーで範囲指定すると、クエリ検索ができる、他の属性はクエリ検索のキーとして使うことはできない。セカンダリインデックスは名前の通り、プライマリキーが1つ目のインデックスなので、2つ目以降のインデックスとして使用する。セカンダリインデックスには、ローカルセカンダリインデックスL(LSI)とグローバルセカンダリインデックス(GSI)がある。ローカルセカンダリインデックスはテーブル作成時に作っておく必要があり、あとから追加することはできない。  
  
テーブルのパーテションキーによって分散されているパーテションに、ソートキーとは違う別のインデックスを作成する。なのでローカルセカンダリインデックスのパーテションキーはテーブルと同じ。  
プロビジョニング済みキャパシティモードは、テーブルの読み込みキャパシティユニット、書き込みキャパシティユニットを使用する。  
  
テーブルのパーテションキーとは無関係の属性でクエリ検索を行いたい場合は、グローバルセカンダリインデックスを使用する。グローバルセカンダリインデックスは後からでも作成できる。パーテションキー、ソートキーのセットをプライマリーキーとは別に設定して検索することが可能。

#### DynamoDB ストリーム
DynamoDBストリームを有効にすると、項目の更新情報がストリームに格納される。DynamoDBの項目が更新されたことをトリガーとして様々なイベント処理を行うことができる。例えば、更新情報を任意のLambda関数に渡して、後続の処理を行っていくことができる。DynamoDBストリーム内でもシャードという単位でデータの格納先が分かれている。DynamoDBストリームはデフォルトでは無料で、あとからでも有効にできる。  
  
DynamoDBストリームを有効にする際は、どの情報をDynamoDBストリームに格納するかを指定する。
- キーのみ:　更新された項目のキー属性のみ
- 新しいイメージ: 更新された後の項目全体
- 古いイメージ:　更新される前の項目全体
- 新旧イメージ:　項目の新しいイメージと古いイメージの全体

#### グローバルテーブル
DynamoDBグローバルテーブルでは、他のリージョンにテーブルのレプリカを作成することができる。このテーブルは、各リージョンでマルチマスターとして書き込み可能なテーブルになる。この機能をグローバルテーブルという。

#### バックアップ
- ポイントインタイムリカバリ  
ポイントインタイムリカバリを有効にすると、過去の35日間分の継続的なバックアップが作成される。有効期間中の任意の時点のテーブルを作成することができる。
  
- バックアップ  
特定時点のバックアップデータを作成しておくことも可能で、バックアップデータをもとに復元することもできる

#### DynamoDB Accelerator(DAX)
DAXを使用すると、インメモリキャッシュを使ってDynamoDBテーブルへの数ミリ秒のレイテンシーを数マイクロ秒に短縮することができる。DAXクラスターは、VPCサブネットグループを指定して作成する。DynamoDBテーブルに対してのアクションと互換性を持っている。DAXに対して書き込むと、DynamoDBテーブルにも書き込まれるのでライトスルーとなる。
  
#### データ操作API
データ操作はすべてAPIで行う。新規項目の追加はPutItemオペレーションで行う。更新目的ではUpdateItem。UpdateItemオペレーションでは、Keyで対象データを指定して、UpdateExpressionで更新式を指定する。GetItemではプライマリキーが必須。responseはJSON形式のデータ。ProjectionExpressionパラメータで、取得する属性を指定する、Consistent Readで強力な整合性を指定できる。DeleteItemでキーを指定して削除することができる。Scanはテーブルの項目すべてをスキャンするので非効率なので、なるべくクエリで検索できるように設計する。DynamoDbでは返されるデータのサイズが最大1MBなので、それを超える場合はページ分割して返される。  
  
大量なデータの書き込みや読み込みをまとめて行うときに、PutItemやGetItemでは非効率な時もある。その場合は、BatchWriteItem, BatchGetItemを使用する。これらを使うことで並列処理ができ、パフォーマンスの向上が期待できる。BatchWriteItem, BatchGetItemは一部の項目の書き込み、読み込みが失敗しても処理を継続する、失敗したレスポンスのUnprocessedItemsに含まれるので、原因調査や失敗処理、場合によっては再試行処理を行う。  
  
複数のテーブルでタイミングを合わせて処理を行う場合は、TransactWriteItems, TransactGetItemsを使用する。トランザクションを成立させる必要上、1つでもリクエストが失敗した場合は処理全体を失敗にする。  
  
DynamoDBのテーブルを抽象化して開発を容易にするためには、JavaにはDynamoDBMapper, .NET(C#)にはオブジェクト永続性モデルがある。それぞれクラスをテーブルにマッピングして開発の効率性を高めコードの可読性を高める。

#### パーテションキーの考慮事項
パーテションキーには分配しやすい属性を使用する・・・ユーザーIDやデバイスIDなど、多くの種類のあるキーが適している。作成日あるいはステータスコードが数種類しかないIDなどは、アクセスが集中するホットパーテションを生みやすくなるため向いていない。  
  
パーテションキーにサフィックスを追加する・・・分配しやすいキーを使用できない場合は、パーテションキーの値に.1から.200を追加することで、パーテションが分散される。

## Lambda
Lambdaを利用すれば、EC2のようにOSの運用や管理、ミドルウェアのインストール、設定、メンテナンス、スケールアップ、アケールアウトなどをしなくても任意のコードを実行できる。
    
### プッシュイベントモデルとプルイベントモデル
プッシュイベントでは、Lambda関数に対してイベントが送信され、送信元のイベントがLambda関数を実行する。なので、Lambda関数のリソースポリシーで、送信元からのInvokeFunctionアクションを許可する必要がある。  
  
プルイベントでは、Lambdaサービスがイベントもとになっているリソースにデータを取りに行く。なので、リソースポリシーは必要ない。Lambdaに割り当てるIAMロールにアタッチするIAMポリシーで、イベントリソースに対しての権限を許可する必要がある。  
  
Lambda関数からの出力はCloudWatch Logsに書き込まれる。必ず出力されるのは以下の内容になる  
- Duration: 1234.56ms・・・Lambda関数の実行時間  
- Billed Duration: 1234ms・・・課金対象の時間,課金単位は1ms
- Memory Size: 123MB・・・Lambda関数に設定しているメモリサイズ
- Max Memory Used: 12MB・・・実際のメモリ最大使用量

### Lambdaデプロイ
1. ランタイムを決めてLambda関数を作成する
2. IAMポリシーをアタッチしたIAMロールを割り当てる
3. ハンドラを持つコードとそのコードが参照するライブラリといった依存関係をZIPにまとめてLambda関数にアップロードする
4. テストして出力をCloudWatch Logsで確認する
5. 運用開始後は、CloudWatch、X-Rayでモニタリングする
Zipファイルが0MBよりも大きい場合は、一度S3バケットにアップロードしてからLambdaへデプロイする。

### Lambdaレイヤー
Lambdaレイヤーを使うと、外部ライブラリなどの依存関係を共有化できる。

### バージョニングとエイリアス
Lambda関数ではバージョニングを作成できるので、コード更新時はバージョンを作成して更新する。バージョンとエイリアスを組み合わせて使うことで、リリースやロールバックを安全に行うことができる。エイリアスにはバージョンを紐づけする。Lambda関数を実行するARNでは、エイリアスも指定できる。

### その他の機能
- 環境変数を設定できる。変更の可能性があるパラメータを環境変数にしておけばコードの変更をすることなく更新できる。  
  
- ほかのリソースと同様にタグを設定できる  
  
- メモリサイズは128~10.240MBの間で設定できる。タイムアウト時間はデフォルト3秒、最長15分まで設定できる。
  
- X-Rayにトレース送信するものもワンクリックで設定できる
  
- Lambdaを指定したVPC内で起動することができる
  
- LambdaでEFSをマウントして使うことができる。EFSのマウントポイントにアクセスする必要があるのでVPC内で起動する。
  
- デフォルトでは同時実行数は、アカウント、リージョン単位で1000となっている。これは極端に考えると1つのLambda関数へのリクエストが同時に1000イベント発生したとしても実行されるということ。
  
- 同時実行数をプロビジョニングしておくこともできる。トリガーイベントが発生して初めて実行されるが、実行環境もその際に作成される。実行環境がない状態から開始されることをコールドスタートという。このコールドスタートに必要な時間は、コンパイルの有無など言語によって異なる。同時実行数をプロビジョニングしておくことで、コールドスタートの時間を短縮できる。
  
- 再試行回数を最大2回まで指定できる。イベントメッセージを指定したキューに送信しておくこともでき、この機能をデッドレターキューという

### Lambdaの制限
同時実行数と関数とレイヤーの合計容量以外は引き上げ申請ができない
- 同時実行数・・・リージョンごとに1000
- 関数とレイヤーの合計容量・・・75GB
- 割り当てメモリ・・・128~10.240MB
- タイムアウト・・・最長15分
- 関数に設定できるレイヤー・・・5つ
- 関数ごとのデプロイパッケージ・・・アップロード時のZIP50MB。レイヤー含む回答合計サイズ250MB
- /tmpディレクトリ・・・512MB

### ベストプラクティス
- 環境変数を使用する
- 共通モジュール、ライブラリをレイヤーで共有する
- 再帰的なコードを使用しない
関数自信を呼び出す関数、関数自信のトリガーイベントを発生させる処理は避ける

## API Gateway
APIにクライアント証明書を設定することができる。バックエンドのWebサーバーで証明書を検証して、直接リクエストを制御することができる。  
APIに対してリクエスト実行できるユーザーを制限できる。インターネットからリクエストを実行するときは、実行を許可するIAMユーザーのアクセスキーID、シークレットアクセスキーを発行し、署名バージョン4で署名を作成してリクエストに含める  
  
IAM認証の代わりに、CognitoオーソライザーまたはLambdaオーソライザーも選択できる。Cognitoユーザープールでサインして取得したJWTトークンをAuthorizationヘッダーに含めて、API Gatewayに対してリクエストを実行する。Lambdaオーソライザーによって、カスタム認証を検証したりサードパーティー製品の認証を検証することができる。
  
作成したAPIの実行数は、デフォルトでリージョンごとに10,000/秒までで、この制限については引き上げ申請が可能。APIステージごとに実行数の設定が可能。バーストは端的に言うと1ミリ秒当たりの制限。  
  
#### 使用料プラン
作成したAPIを顧客に公開し、リクエストに応じた課金請求を行うとする。もしくは、顧客ごとに制限回数を設けたい場合は、使用料プランを利用できる。APIキーを作成して、使用料プランに紐づけることができる。APIリソースのメソッドリクエストの【APIキーの必要性】をtrueに設定する。これでAPIキーを使用していない顧客はリクエストが実行できなくなる。
  
#### インポートエクスポート
ステージからAPIの設定をSwagger形式でエクスポートできる。エクスポートしたJSONもしくはYAMLのSwaggerファイルはAPI Gatewayにインポートしたり、SAMでサーバレスアプリケーションにAPIを含める際に使用できる。


## SQS
SQSではリージョンを選択してキューを作成する。キューはメッセージの入れ物で、作成したキューに対してメッセージを送信したり、受信したり、処理済みのメッセージを削除したりする。一般的にキューにメッセージを送る側をプロデューサー、メッセージを受信して処理する側をコンシューマーと呼ぶ。
  
#### 可視性タイムアウト
大量なメッセージを処理する場合など、コンシューマーは複数用意されることがある。例えばコンシューマーAがメッセージを受信して処理中に、コンシューマーBが受信してしまうと処理が重複することになる。これを防ぐための仕組みが、可視性タイムアウト。
  
コンシューマーAがメッセージを受信したタイミングで、そのメッセージはほかのコンシューマーからは見えなくなる。Aが処理を正常終了したらメッセージを削除する。これでメッセージの処理が重複することはない。
  
コンシューマーAがメッセージによる処理の途中で何らかの障害やエラーが発生した場合に備えて、メッセージがもう一度見えるようになる秒数を指定しておく。例えば、60秒とすると、60秒経過後にメッセージが見えるようになるからAに障害が発生したとしても、Bが処理をリトライできる。
  
可視性タイムアウトは、VisibilityTimeoutパラメータで秒数を指定できる。VisibilityTimeoutはメッセージの受信リクエストごと、もしくはキューの属性でメッセージデフォルト値として設定できる。

#### デッドレターキュー
可視性タイムアウトの制限回数を決めておき、制限に達したメッセージをあらかじめ指定しておいた他のキューに移動することができる。この機能がデッドレターキューで、キューの属性RedrivePolicyのMaxReceiveCountで最大受信数を設定できる。

#### ロングポーリング
コンシューマーはキューに対してメッセージの受信リクエストを実行する。プロデューサーからキューにメッセージが送信されるタイミングが特に決まっていない場合、コンシューマーは定期的に受信リクエストを実行する。そして、メッセージがあれば受診して処理を実行する。この定期的な受信リクエストの実行をポーリングと呼ぶ。  
  
SQSの料金はAPIリクエストに対する料金で、1か月あたり100万回リクエストまで無料、100万回を超えた分は1リクエスト当たり東京リージョンでは0.0000004USDと非常に安価。メッセージが0件の受信リクエストにも請求の対象となるので、メッセージが0件の受信リクエストをなるべく減らした方がコストの最適化につながる。受信リクエスト実行時にメッセージが0件の場合は、WaitTimeSecondsで指定した秒数だけ待機する。待機中のメッセージが送信され、受信可能になった場合は、そのメッセージを受信する。待機秒数は最大20秒まで設定できる。待機秒数はメッセージの受信リクエスト事のWaitTimeSeconds、またはキュー属性のReceiveMessageWaitTimeSecondsで設定できる

#### 共有キュー
SQSキューには、キューポリシーが設定できる。リクエスト料金はキューを作成した側のアカウントに請求される。

#### キューのタイプ
キューには標準キューとFIFOキューがある。

- 標準キューの特徴   
1. 無制限のパフォーマンス  
1秒当たりのAPIリクエストの回数はほぼ無制限。メッセージの送受信、削除などのメインの処理を無制限に実行することが最初からできる。SQSを使って構築したシステムやサービスが成長したからといって、性能のスケールアップについてユーザーが調整する必要はなく、そのままスケーラビリティの実現につながる。  
  
2. 少なくとも1回以上の配信  
コンシューマーが受診して処理して削除するまでを1回の配信としたときに、削除したメッセージや可視性タイムアウトに入ったメッセージを他のコンシューマーが受診してしまうことがある。これは、無制限のパフォーマンスを実現することを優先しているために発生しうる制約ともいえる。冪等性の設計をして、同じメッセージを受信しても結果を変えないようにする
  
3. 先入先出はベストエフォート  
プロデューサーから先に送信されたメッセージから順に受信できるとは限らない。
  
  
- FIFOキューの特徴
1. 1秒間で300回のAPIリクエスト・・・1回あたりメッセージ10個の処理が可能なので、トランザクションとしては3000  
2. 1回のみの配信をサポート
3. 先入れ先出をサポート

2と3の要件があったときはFIFOキューを選択する

#### キューの作成、管理
CreateQueue・・・キューを新規作成する。属性にはキューに格納するメッセージのデフォルト値を設定することができる。  
SetQueueAttributes・・・既存のキューの属性を変更する。CreateQueueで紹介したパラメータを設定できる  
GetQueueAttributes・・・既存のキューの属性を取得して確認する  
GetQueueUrl・・・キューにAPIリクエストを実行するときのエンドポイントはキューURL  
ListQueues・・・指定したリージョンのキューURLの一覧を取得できる。QueuenamePrefixを使って名前でフィルタリングすることもできる。  
DeleteQueue・・・キューにメッセージがあるかどうかに関係なく、キューを削除する。  
  
  
#### メッセージの操作
SQSキューへのメッセージの送信、受信、削除はAPIリクエストによって操作する。  
  
SendMessage・・・プロデューサーがメッセージを送信する  
ReceiveMessage・・・コンシューマーがメッセージを受信、ポーリングする。  
DeleteMessage・・・コンシューマーが処理が渉猟したら、メッセージを削除する。  
DeleteMessageBatch・・・複数のメッセージを削除するときに使用する。ReceiptHandleの配列をパラメータで指定して最大10このメッセージを削除する
PurgeQueue・・・指定したSQSキューのメッセージをすべて削除する。DeleteQueueはキューそのものの削除
  
#### Amazon SQS Extended Client Library
SQSでは、扱えるメッセージの最大サイズは256KB。256KBを超えるサイズのメッセージは、S3バケットに格納する設計がよくみられる。Java用のExtended Client LibraryはSQS用の拡張クライアントライブラリであり、SQSとS3を組み合わせて256KBを超えるメッセージを扱うのに便利。Extended Client Libraryでは以下のことを少ないコードで開発できる
  
- メッセージを常にS3に保存するか、メッセージのサイズが256KBを超える場合のみ保存するかを指定する
- S3バケットに格納されている1つのメッセージオブジェクトを参照するメッセージをSQSキューに送信する
- S3バケットからメッセージオブジェクトを取得する
- メッセージオブジェクトをS3バケットから削除する
    

## SNS
SNSを使うと、Notificationというとおり、様々なメッセージ通知を効率的に行うことができる。  

### ファンアウト
SNSとSQSでファンアウトという設計がよくある。1つのメッセージを複数のサブスクライバーにプッシュする。そして並列処理をする。例えば、フォームから注文された内容をDynamoDBテーブルに保存する処理と、社内のグループウェアに通知する処理があった場合、SNSとSQSを組み合わせると簡単に実装できる。サブスクリプションを設定するときに、rawメッセージを有効にすると、SNSにパブリッシュされたメッセージをそのまま送信する。rawメッセージを有効にしない場合は、属性情報と合わせてJSONエンコードされる。
  
### SNSトピックの作成
- CreateTopic・・・トピックの作成をする。トピック名をパラメータに設定する
- Subscribe・・・サブスクリプションを設定する。
- DeleteTopic・・・トピックを削除する。トピックのARNを指定する。
- Publish・・・メッセージの操作はPublish。SNSトピックのメッセージはサブスクライバーにプッシュされるので、受信や削除が必要ない。送信するトピックARN、メッセージ本文、オプションで件名やメッセージ属性をパラメータに指定する。
  
## Amazon MQ
Amazon MQは主に移行向けのサービス。広く使われているOSSのApache ActiveMQまたはRabbitMQから選択できる。このうちいずれかをオンプレミスで使用しているシステムの場合は、そのまま移行することができる。またこれらのOSSが採用しているJMS, NMS, AMQP, STOMP, MQTT, WebSocketなどがそのまま使用できる。

## Amazon Kinesis
ストリーミングデータをリアルタイムに収集し、加工や判定処理を行い分析するためのサービス。  
  
ストリーミングとは、端的にいうと順次処理。どこかからファイル全体をダウンロードしたり、大きなデータセットがすべてアップロードされてからまとめて行うバッチ処理ではなく、アップロードされたもの、ダウンロードされたものから、都度、処理をしていく。  
  
一般に、動画や音楽を配信する際に広く使われているが、1本の映画や楽曲を完全にダウンロードしてから再生するのではなく、データの転送と再生を順次に行っている。このような処理をニアリアルタイムな処理と呼ぶ。完全なリアルタイムではなく、リアルタイムに近い処理という意味。  
  
バッチ処理よりも、ニアリアルタイムなストリーミング処理が必要になった背景の1つに、バッチ処理ではタイミングが遅いという課題があった。インターネットの普及に伴い、企業は俊敏性を求められる。ユーザーの行動に対し、いち早く何らかのアクションを起こす必要がある。

#### Kinesis Video Streams
ビデオデバイスからAWSへ動画を簡単かつ安全にストリーミングできる。Rekognition videoと組み合わせて分析などを行うなどができる。

#### Kinesis Data Streams
数十万のデータ送信元から1秒当たり数ギガバイトのデータを継続的に送信できて、リアルタイムなデータストリーミング処理に使用される

#### Kinesis Data Firehouse
ストリーミングデータをS3、Redshift、Elastic search Serviceなどにロードできる。複雑なデータ処理が不要な場合に、最も簡単に使用できる。

#### Kinesis Data Analytics
SQLやApache FlinkでKinesis Data Streamsなどのストリーミングデータのリアルタイム分析ができる
  
   
Kinesisにデータを送信する側をプロデューサー、Kinesisのデータを受信して処理する側をコンシューマーを呼ぶ。プロデューサー側の開発にはKinesis Producer Library(KPL)、コンシューマー側の開発Kinesis Client Library(KCL)を使用することもできる。シャード単位で送信・受信処理のキャパシティが決定される。キャパシティを増やす必要がある場合は、シャードを増やすことを検討する。  
  
## AWS Step Functions
マイクロサービスを組み合わせて簡単にワークフローを作成・制御することができる。Step Functionsではステートを管理するステートマシンというリソースを作成する  
  
### Step Functionsのメリット
例えば複数のLambda関数でマイクロサービスを構築した際に、Lambda関数同士の直列実行や並列実行、再試行、分岐などの制御を実装しようすると、その制御のためのロジックをコーディングしなければならなくなる。この制御ロジックを簡単に実装できるのがStep Functions  
  
開発者はStep Functionsを使用することにより、制御ロジックの実装が容易になり、制御そのものをStep Functionsに任せることができ、処理コードの開発とモニタリングに注力できる。  
  
指定したLambda関数を実行して、その結果により分岐や再試行をしたり、指定した2つのLambda関数を並列で実行して、両方が正常完了するのを待って最終処理を行い一連の処理を終了させたりすることができる  
  
ステートマシンはJSONフォーマットのステートメント言語で記述する。ステートマシンの実行結果も可視化されたワークフロー図で確認できる。

### Step Functionsのタイプ
Step Functionsのマネジメントコンソール作成画面には、サンプルテンプレートが用意されている。TaskタイプにはLambda関数、アクティビティ、他のAWSサービスとの統合が指定できる。Lambda関数の場合はResourceにLambda関数のARNを指定する。
  
アクティビティはStep Functionsで名前を設定して作成するだけで、作成したアクティビティをタスクで指定する。アクティビティワーカーは、EC2やECSコンテナ、オンプレミスアプリケーションなど外部のアプリケーション。
