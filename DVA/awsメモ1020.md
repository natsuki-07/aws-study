# AWS Certified Developer - Associate

## ECS
### ECSの概念
簡単に言うと、クラスター(複数のEC2インスタンスの集合)の上で、Dockerコンテナを使ってServiceを作動させるもの  
↓かなり長くなりそうなので  
[ECSの概念整理](https://qiita.com/NewGyu/items/9597ed2eda763bd504d7)
  
ECSのタスク定義においてIAMロールを設定するためには`ECS_ENABLE_IAM_ROLE=true`とすることが必要。設定上の問題でタスクがIAMタスクロールが見つけられない場合は、代わりにEC2インスタンスロールが使用される
   
### ECSとALB
ECSはALBと連携してECAのクラスターやタスクに対するトラフィック制御を実行することができる。ALBのターゲットにポート番号を指定して詳細な制御を実施することも可能。  
ELBのトラフィック転送にはオーバーレイネットワークなどDocker向けネットワーク構成ではなく、ロードバランサのノードとECSホスト間のネットワークがそのまま利用される。そのためECSのELB構成パターンとしてはELBの種類とECSホストのポート構成の組み合わせになる。  
  
### タスク配置戦略
タスク配置戦略はタスク配置またはタスク終了でインスタンスを選択するためのアルゴリズム。タスクの実行時または新しいサービスの作成時にタスク配置戦略を指定できる。
- Binpack:  
CPUまたはメモリの最小利用可能量に基づいてタスクを配置する。これにより使用するインスタンス数を最小限に抑える。  
- Random:  
タスクをランダムに配置  
- Spread:  
指定された値に基づいてタスクを均等に配置する。有効な値はinstanceld、またはattribute:ecs.availability-zoneなどのコンテナインスタンスに適用される任意のプラットフォームまたはカスタム属性。サービスタスクはそのサービスからのタスクに基づいて分散される。スタンドアロンタスクは同じグループからのタスクに基づいて分散される。
    


### 署名バージョン4
HTTPで送信されるAWS APIリクエストに認証情報を追加するプロセスのこと。セキュリティのためAWSへのほとんどのリクエストはアクセスキーで署名する必要がある。AWSへのリクエストはアクセスキーを利用する際に署名バージョン4を利用してアクセスが許可される。
  
### AppSpec
AppSpecはCodeDeployで実行するデプロイ処理の内容で、デプロイでどのようなことを処理させるか、具体的な内容を記述していくYAMLフォーマットで構成されたファイル。  
CodeDeployがEC2やS3、Githubにあるアプリケーションのリビジョンをどのようにインストールするか決定するYAMLフォーマットのファイル。また同様にデプロイの様々なライフサイクルイベントをフックして処理を実行するか決定する。  
ファイルの名前は必ず`appspec.yml`とし、ルートディレクトリに配置しなければいけない。
  
ECSのコンテナが複数のタスクを定義しており、それぞれの資格情報にアクセスできないようにするためにはタスクごとに権限設定をすることが必要となる。各タスクにIAMロールを割り当てることで権限を分けることが可能。
  


## KDS
### KDSのシャード
シャードはストリーム内の一位に識別されたデータレコードのシーケンス。ストリームは複数のシャードで構成され、各シャードが容量の1単位となる。データ転送速度が増加した場合はストリームに割り当てられたシャードを分割(増加)することでパフォーマンスを向上させることが可能。
  
### KDSのストリームデータの暗号化
HTTPSエンドポイントを使用することでHTTPSによるデータ通信が実施されてクライアント間でデータを暗号化し、転送されているレコードの盗聴を防止する。  
またKinesis Streamsは保存中のデータに対するサーバーサイド暗号化を実施して、一時的に蓄積されたストリームデータを保護することができる。PutRecordまたはPutRecords APIを使用してKinesis Streamに含んだデータレコードやパーティションキーはAWS KMSのマスターキーを使用して暗号化されている。  
[KDS用のサーバー側暗号化](https://docs.aws.amazon.com/ja_jp/streams/latest/dev/what-is-sse.html)  
  
### Kinesis Client Library(KCL)
Kinesis data streamのデータを使用および処理する機能を提供して、Kinesisを組み込んだアプリケーションを構築することができる。このタイプのアプリケーションはKinesis処理におけるコンシューマと呼ばれ、KCLは分散コンピューティングに関連する多くの複雑なタスクを処理する。特定のアプリケーションのKinesisではシャードごとに最大1つのKCL用のEC2インスタンスが使用できる。
  
### KDS　データ保持期間
KDSのデフォルトのデータ保持期間は24時間に設定されていて、最大では168時間保持できる。24時間経つとデータが失われてしまうので、1日おきにデータを処理するように設定すると前日のデータが消えてしまっている可能性がある。
  
  
   
### CodeDeployのHooks
CodeDeployでは`Hooks`という機能でライフサイクルイベントを設定して、デプロイフェーズに応じた任意のスクリプトを実行することができる。このHooksのスクリプト実行ポイントは複数あり、それらのポイントを細かく制御することが可能。フックスクリプトはアプリケーションのアーカイブにバンドルしてS3やCodeCommitにアップロードする。例えば`ValidateService`はデプロイイベントの最後の段階でデプロイが正常に完了したことを確認するために使用される。
  
### CodeDeploy Agent
CodeDeployソフトウェアパッケージをインスタンスにインストールして設定すると、そのインスタンスをCodeDeployによるデプロイ時に使用できるようになる。Agentがインストールされている場合、設定ファイルはインスタンスに配置される。このファイルは、エージェントの動作を指定するために使用され、インスタンスとやり取りするときに使用するCodeDeployのディレクトリパスおよびそのほかの設定を指定することができる。
  
  
  
### S3のサーバーアクセスログ
サーバーアクセスログはアクセスログのレコードごとに1つのアクセスリクエストの詳細として、リクエスタ、バケット名、リクエスト時刻、リクエストアクション、レスポンスのステータス、エラーコードなどの情報が取り込まれる。サーバーアクセスログにはS3バケットに対するリクエスト詳細が記録されるため有益だが、ストレージデータ量を増加させるというデメリットもある。
  
  　
  
  
## Elastic Beanstalk
### Elastic Beanstalk環境にHTTPSを設定
HTTPSを使用するには、環境内にロードバランサー用のHTTPSリスナーを設定する必要がある。ALBはHTTPSリスナーをサポートしており、HTTPSによるトラフィック制御が可能。実際の設定においてはElastic Beanstalkコンソールまたは設定ファイルを使用してセキュアリスナーを設定して証明書を割り当てる。その際に`ebextensionファイル`を作成してロードバランサーを構成することになる。ALBの場合は`.ebextensions/https-reencrypt-alb.config`を使用する。  
  
### Elastic BeanstalkとX-Rayの統合
ElasticBeanstalkのコンソールにおいて有効化するか、設定ファイルを使用してアプリケーションソースコードにX-Rayデーモンを設定することが必要。Elastic Beanstalkプラットフォームには、デーモンを自動的に実行する設定オプションがある。  
ソースコードに設定ファイルを含めて利用するためには`.ebextensions/xray-daemon.config`ソースコードの`.ebextensions`ディレクトリに`xray-daemon.config`構成ファイルを含めることが必要で、これによりX-Rayデーモンを有効にすることができる。
  
### EB環境へのデプロイ
デプロイポリシーも含めデプロイを処理するいくつかのオプションがあり、バッチサイズやデプロイ中のヘルスチェックの動作を設定できる。デフォルトでは一括デプロイを実施する。EB CLIで環境を作成し、それが自動スケーリング環境である場合は、ローリングデプロイが使用される。  
- All at once:  
新しいバージョンをすべてのインスタンスに同時に展開する。環境内のすべてのインスタンスは展開が行われている間、短時間サービスが停止する。これが展開に必要な合計時間を最短にする方法  
  
- Rolling:  
Elastic Beanstalkは環境のEC2インスタンスを複数のバッチに分割し、アプリケーションの新しいバージョンを一度に1つのバッチにデプロイする。これにより、環境内の残りのインスタンスは古いアプリケーションバージョンを実行した状態になる。つまりローリングデプロイ中は、アプリケーションの古いバージョンでリクエストを処理するインスタンスもあり新しいバージョンでリクエストを処理するインスタンスも存在する。  
  
- Rolling with additional batch:  
新しいバージョンをバッチで展開するが、最初にインスタンスの新しいバッチを起動して、展開プロセス中に完全な容量を確保する。  
  
- Immutable:  
変更不可能な更新を実行して、古いバージョンを起動しているインスタンスと並行しながら別のAutoScallingグループにあるアプリケーションの新しいバージョンを起動しているインスタンスのフルセットを起動する。部分的に完了したローリングデプロイにより発生する問題を防止できる。新しいインスタンスがヘルスチェックをパスしなかった場合Elastic Beanstalkはそれを終了し、元のインスタンスをそのまま残す。
  
  
  
   

## DynamoDB
### DynamoDBのキー
DynamoDBはプライマリーキーを使用してテーブルの各項目を一意に識別するように設定する。プライマリーキーとして複号キーを設定する場合は、最大で2つの属性を利用して複号キーを作成する。DynamoDBテーブルの主キーとして構成できる属性の最大数は2となる。
- パーテションキー  
パーテションキーという1つの属性で構成されたシンプルなプライマリキー。パーテションキーの値を内部ハッシュ関数への入力として使用する。ハッシュ関数からの出力により保存される項目が決まる。
  
- 複合プライマリキー  
複合プライマリキーは2つの属性で構成される。最初の属性はパーテションキーであり、2番目の属性はソートキーである。同じパーテションキー値を持つすべての項目は、ソートキー値でソートされてまとめて保存される。パーティションキーとソートキーが存在するテーブルでは、同じパーテションキー値が2つの項目に割り当てられることがあるが、ソートキー値は2つの項目で異なる必要がある。
  
### グローバルセカンダリインデックスとローカルセカンダリインデックス
DynamoDBテーブルに対してプライマリーキー以外を利用した複雑な検索が必要な場合は、大体のソートキーを利用してキーを追加することができ、これをローカルセカンダリーインデックスと呼ぶ。そのためにはテーブル作成時にローカルセカンダリインデックスを追加することが必要となる。アプリケーションにソートキーを提供するために1つ以上のローカルセカンダリインデックスを作成してそれらのインデックスに対してQueryまたはScanリクエストを実行できる。これによってクエリの検索性を向上させることが可能となる。ローカルセカンダリインデックスのデータは、ベーステーブルと同じパーティションキーで編成されるがソートキーは異なる。ソートキーを利用することで異なるでメンション間でデータ項目に効率的にアクセスできる。クエリまたはスキャンの柔軟性を高めるためにテーブルごとに最大5つのローカルセカンダリインデックスを作成できる。  
  

グローバルセカンダリインデックス(GSI)は、既存のテーブルに対して自由に追加できるインデックス。GSIはハッシュキーテーブルによっては様々な属性をクエリ基準に使用して、いろいろな種類のクエリを実行する必要がある。このような要件に対応するために、1つ以上のグローバルセカンダリインデックスを作成して、DynamoDBでそのインデックスに対してQueryリクエストを発行できる。これによりクエリ処理を効率的に高速に実行することができる。  
[DynamoDBセカンダリインデックス](https://qiita.com/uenohara/items/c52c2eef991fd6c8a405)  
[DynamoDBのキー・インデックスについてまとめてみた](https://qiita.com/shibataka000/items/e3f3792201d6fcc397fd)  
  
### DynamoDBの有効期限TTL
DynamoDBの有効期限(TTL)を使用することでデータを自動的に失効させて、テーブルに保存された項目を自動的に削除することができる。TTLを有効にすると項目ごとに削除のタイムスタンプを設定し、関連性のあるレコードのみにストレージ使用料を制限する。
  
### DynamoDB BatchGetItem
`BatchGetItem`操作による読み取り処理によって複数のアイテムをまとめて読み取るバッチ処理が実行できる。この操作を使用するとアプリケーションからDynamoDBへのデータ処理リクエスト回数を減らすことができる。BatchGetItemオペレーションは、プライマリキーを使用して複数のテーブルから複数の項目の属性を返す。1回のオペレーションで取り出すことができる項目の最大数は100で、取り出される項目は1MBのサイズ制限を受ける。
  
### DynamoDBストリームとLambda
DynamoDBストリームはDynamoDBに対する項目の追加、変更、削除をイベントとして検出できる機能。DynamoDBストリームを使うことで項目が追加・変更されたことをトリガーとしてプッシュ通知を飛ばしたりといった実装が可能となる。DynamoDBストリームをLambda関数に関連付けるにはLambda側にDynamoDBストリームのAmazonリソースネーム(ARN)を関連付ける設定が必要となる。これによってLambda関数はDynamoDBストリームをポーリングして新しいストリームレコードを検出すると、Lambda関数を同期的に呼び出すことができる。
  
### キャパシティーユニット
1つの読み込みキャパシティーユニット(RCU)は最大サイズ4KBの項目に対して、１秒当たり１回の強力な整合性のある読み込み、あるいは1秒当たり2回の結果整合性のある読み込みを実施できる。4KBを超える項目に対してはより多くのRCUを消費する
  
1つの書き込みキャパシティーユニット(WCU)は最大サイズが1KBの項目に対して、1秒当たり1回の書き込みを表す。  
[DynamoDB のプロビジョンされた容量テーブルの設定の管理](https://docs.aws.amazon.com/ja_jp/amazondynamodb/latest/developerguide/ProvisionedThroughput.html)
  
### アトミックカウンター
UpdateItemオペレーションを使用してアトミックカウンターを実装できる。アトミックカウンターは書き込みリクエストを妨害することなく無条件で増分される数値属性である。アトミックカウンターではUpdateItemを呼び出すたびに数値が増加されてカウントされることになる。現在値に関係なく数値はインクリメントされ、UpdateItemオペレーションが失敗した場合、アプリケーションはオペレーションを再試行する。そのため二重計上の可能性が発生するため、アトミックカウンターは厳密なカウンターが必要な場合は使用できない  
  
  
    






### AssumeRole
一時認証情報を引き受けるためにアプリケーションはAWS STSの`AssumeRole API`オペレーションを呼び出すことで使用するロールのARNを返す。この操作によって一時的な資格情報によるセッションが作成される。AWS STSにはAWSリソースへのアクセスを制御できる一時的セキュリティ認証情報を持つ信頼されたユーザーを作成及び提供するオペレーションが含まれる。  
IAMロールにはアイデンティティベースポリシー、Permissions boundary、信頼ポリシーの設定ができる。AWSリソースにIAMロールを引き渡す際には`PassRole`の権限が必要となる。AssumeRoleすることでIAMロールに設定された権限を引き受けることができる。このAssumeRoleを実行する際はSTSを介しており、行うのはIAMユーザーだけではなくまた重ねがけもできる。  
  
### CloudWatchでAPIの監視
CloudWatchはAPI Gatewayから生データを収集・処理してリアルタイムで確認可能なメトリックに変換して2週間分のデータを記録する。デフォルトではAPI Gatewayメトリックデータは1分間隔でCloudWatchに自動的に送信される。  
API Gateway 名前空間には以下のメトリクスが含まれる。
- 4XXError: 指定された期間に取得されたクライアント側のエラー数  
- 5XXError: 指定された期間に取得されたサーバー側のエラー数  
- CacheHitCount: 指定された期間内にAPI キャッシュから配信されたリクエストの数  
- Count: 指定された期間内のAPIリクエストの合計数  
- IntegrationLatency: API Gatewayがバックエンドにリクエストを中継してからレスポンスを受け取るまでの時間  
- Latency: API Gatewayがクライアントからリクエストを受け取ってからクライアントにレスポンスを返すまでの時間  
  
### CloudWatchエージェント
CloudWatchはデフォルトではEC2インスタンスの内部情報(メモリやディスク情報)は取得できない。これはAWSが各ユーザーのインスタンス内部の情報が取得できないように設計されているからである。そこでCloudWatchエージェントをEC2インスタンスにインストールすることで、オペレーティングシステム全体でEC2インスタンスからより多くのシステムレベルのメトリクスを収集する。子のメトリクスにはEC2インスタンスのメトリクスに加えてゲスト内メトリクスを含めることができる。
  
### KMSデータキーの生成
APIの`GenerateDataKey`を利用する。返答されたプレーンテキストデータキーを使用して最終的にデータを暗号化するためには`GenerateDataKeyWithoutPlaintext`を利用する。GenerateDataKeyWithoutPlaintextは一意のデータキーを生成するAPIで、このAPIコールによって指定した顧客マスターキーで暗号化されたデータキーを作成することができる。  
`Encrypt`でデータキーを暗号化、`Decrypt`で復号化、`CreateGrant`でカスタマーマスターキーの作成許可を設定する
  
[KMSの仕組み](https://dev.classmethod.jp/articles/10minutes-kms/)  
  
  
  
   

### Secrets Manager
Secrets Managerを使用するとコード内のハードコードされた認証情報をSecrets ManagerへのAPIコールに置き換えてプログラムでシークレットを取得することができる。またSecrets Managerを設定することで指定したスケジュールに従って自動的にシークレットを更新するようにできる。これにより長期のシークレットを短期のシークレットに置き換えることが可能となる。  
Secrets ManagerもSystem Managerも同じような機能だが、パラメータやシークレット情報に対するスパイクアクセスが予想される場合はSecrets Managerを利用した方が性能上限が高いため有益。またRDSの接続情報の自動更新が実施できるのも利点となるが、欠点としてはSystem Managerが無料なのに対してSecrets Managerは有料となる点である。  
  
- Systems Managerパラメータストアは設定データ管理と機密管理のための安全な階層型ストレージで、データをパラメータ値として保存できる。
  
### RDS MYSQLエラーログ
MySQLでは、エラーログ、スロークエリログ、一般ログの3つのログをモニタリングできる。エラーログはデフォルトで生成される。DBパラメーターグループを設定することで、ス路0クエリと一般ログを生成できる。ログの中でもトラブルシューティングのために実行にかかったすべてのSQLステートメント内容を収集することができるのはスロークエリログである。  
  
- 一般ログ:  
mysqldの実行内容の一般的な記録。サーバーはクライアントが接続または接続解除したときに情報をこのログに書き込みクライアントから受け取った各SQLステートメントをログに記録する。一般クエリーログは、クライアント側でエラーが疑われるとき、クライアントがmysqldに送信した内容を正確に知りたい場合に役立つ。
  
- エラーログ:
エラーログにはmysqldが開始および停止された時期を示す情報とサーバーが実行中に発生したあらゆるクリティカルエラーが格納される。自動的にチェックまたは修復することが必要なテーブルがmysqldで検出された場合、エラーログに警告メッセージが書き込まれる。  
  
- スロークエリログ:
スロークエリログは、実行に要した時間が`long_query_time`秒を超え、少なくとも`min_examined_row_limit`行を検査する必要があったSQLステートメントで構成される。`long_query_time`の最小値およびデフォルト値はそれぞれ0および10である。値はマイクロ秒の精度まで指定できる。ファイルへのロギングの場合、時間はマイクロ秒の部分も含めて書き込まれる。テーブルへのロギングの場合、時間の整数部のみ書き込まれマイクロ秒部分は無視される。
  
  
  
  

## Lambda
### Lambdaの同時実行数
LambdaはデフォルトではLambda関数の実行と保存に使用できるコンピューティングおよびストレージリソース量が制限されている。Lambda関数の同時実行数は1000までに制限されている。制限はリージョンごとに適用されていて、AWSに上限緩和申請することで制限を引き上げることができる。Lambdaの同時実行数の計測は以下のように考える。  
```
同時実行=(1秒当たりの呼び出し数)×(平均実行時間(秒))
```
例えばLambda関数が平均10秒かかり、1秒当たり100個のイベントを発行するとLambda関数を1000同時に実行することになり、制限ぎりぎりとなってしまう。  
  
Lambda関数の同時実行数とは同時にリクエストを処理するインスタンス数を指す。実行数制限はすべてのLambdaで共有される。つまりインスタンス1が先に同時実行を多く実行してしまうと、インスタンス2が実行できる数がすぐに上限に達してしまう可能性がある。
  　
### Lambda /tmp
Lambda関数においてファイルを一時的に保存する際はローカルディレクトリ/tmpを使用する。最大512MBとなり、実行環境が停止された際に維持され、複数の呼び出しに使用できる一時的なキャッシュを提供する。
  
### Lambdaオーソライザー
Lambdaオーソライザーは、Lambda関数を使用してAPIへのアクセスを制御するAPI Gatewayの機能。OAuthやSAMLなどのベアラートークン認証戦略を使用する、または発信者IDを判断するためにリクエストパラメータを使用するカスタム認証スキームを実装する場合に利用される。クライアントがAPIのメソッド1つにリクエストを送信すると、API GatewayはLambdaオーソライザーを呼び出す。これは発信者IDを入力として受け取り、IAMポリシーを出力として返す。  
Lambdaオーソライザーには次の2種類がある。
  
- トークンベースのLambdaオーソライザー(TOKENオーソライザーとも呼ばれる)がJSONウェブトークンやOAuthトークンなどのベアラートークンで発信者IDを受け取る。
  
- リクエストパラメータベースのLambdaオーソライザー(REQUESTオーソライザーとも呼ばれる)は、ヘッダー、クエリ文字列パラメータ、stageVariables、および$context変数の組み合わせで発信者IDを受け取る。
  
### API Gatewayエンドポイント
API GatewayとLambda関数やWebアプリケーションと統合する際は、使用する統合エンドポイントのタイプと、統合エンドポイントに対するデータの受け渡し方法に応じてAPI統合タイプを選択する。  
Lambda関数とAPI Gatewayを統合する場合、Lambdaプロキシ統合またはLambdaカスタム統合を使用できる。その際にHTTPエンドポイントを使用するにはHTTPプロキシ統合またはHTTPカスタム統合を使用することを求められる。AWS サービスアクションの場合、非プロキシタイプのAWS統合のみを使用する。API Gatewayはモック統合もサポートしており、API Gatewayはメソッドリクエストに応答する統合エンドポイントとして機能する。  
  
#### サポートされている統合タイプ
- AWS:  
AWS統合は、APIはAWSのサービスアクションを公開する。AWS統合では統合リクエストと統合レスポンスの両方を設定し、メソッドリクエストから統合リクエストへの、また統合レスポンスからメソッドレスポンスへのデータマッピングを設定する必要がある。  
- AWS_PROXY:  
AWS_PROXY統合には様々な用途に柔軟に利用できる合理化された統合設定があり、APIメソッドをLambda関数呼び出しアクションと統合できる。この統合は、統合Lambda関数との間の直接的なやり取りに依存する。Lambdaプロキシ統合とも呼ばれユーザーが統合リクエストまたは統合レスポンスを設定することはない。API Gatewayはクライアントから受け取ったリクエストをバックエンドのLambda関数への入力として渡す。統合Lambda関数はこの形式の入力を受け取り、使用可能なすべてのソースからの入力を解析する。その後出力形式に従って結果を返す。  
  
- HTTP:  
HTTP統合は、APIがバックエンドのHTTPエンドポイントを公開することを可能にする。HTTP統合(HTTPカスタム統合とも呼ばれる)では、統合リクエストと統合レスポンスの両方を設定する必要がある。メソッドリクエストから統合リクエストへの、また統合レスポンスからメソッドレスポンスへのデータマッピングを設定する必要がある。  
  
- HTTP_PROXY:  
HTTP_PROXY統合では、クライアント1つのAPIメソッドで合理化された統合設定を使用して、バックエンドのHTTPエンドポイントにアクセスできる。ユーザーが統合リクエストまたは統合レスポンスを設定することはない。API Gatewayはクライアントから受け取ったレスポンスをHTTPエンドポイントに渡し、HTTPエンドポイントから送り出されたレスポンスをクライアントに渡す。このようにHTTPエンドポイントを介して対話が行われるためクライアントとバックエンドがAPI Gatewayの介入なしで直接対話できる
  
- MOCK:  
MOCK統合では、API Gatewayはリクエストをさらにバックエンドに送信することなくレスポンスを返す。このタイプの統合はバックエンドの使用料金が発生することなく統合設定のテストに使用したり、APIの共同開発に使用したりできるためAPIのテストに活用できる。共同開発では、チームはMOCK統合を使用して、他のチームが所有するAPIコンポーネントのシミュレーションを設定することで、自分たちの開発成果を区分することもできる。またCORS関連のヘッダーを返してAPIメソッドがCORSへのアクセスを許可するようにもできる。
  
  
### X-Ray
X-Ray SDKではX-Ray APIを使用してサンプリングルールの取得、サンプリング結果の報告、およびクォータ取得を行う。サンプリングルールにおけるリザーバサイズは固定レートを適用する前に記録する1秒当たりのトレースの目標数となる。リサーバはすべてのサービスに累積的に適用されるため、直接使用することはできない。ただし、0以外の場合はX-Rayがクォータを割り当てるまでリサーバから1秒に1個とレースを借りることが可能。クォータを受信する前に1秒ごとに最初のリクエストを記録し、追加のリクエストに固定レートを適用する。固定レートは0~1.00の10進数  
  
1秒あたりのサンプリングされた要求の合計を計算する方法  
```
サンプリングリクエスト数 = リザーバーサイズ + ((1秒あたりの着信リクエスト - リザーバサイズ) * 固定レート)
```
  
  
### SAMとCloudFormation
CloudFormationテンプレートを利用してLambda関数を利用したサーバレスアプリケーションのインフラを構成するためには、CloudFormationテンプレートの`AWS::Serverless Transform`セクションにおいてAWS SAMのバージョンを指定することが必要。CloudFormationによってホストされるマクロであるAWS::Serverless TransformセクションはAWS Serverless Aplication Model構文で記述されたテンプレート全体を受け取り、CloudFormationテンプレートに変換および拡張することができる。CloudFormationにおいてサーバーレスアプリケーションを設定する場合は、Transformセクションで使用するAWS SAMバージョンを指定する。変換を指定する場合は、AWS SAM構文を使用してテンプレート内のリソースを宣言できる。  
  
### Elastic Cacheキャッシュ戦略
キャッシュするデータとデータへのアクセスパターンに基づいて、キャッシュを入力し維持するために実装する戦略。  
- 遅延読み込み戦略:  
必要なときにのみキャッシュにデータを読み込むキャッシュ戦略
  
- 書き込みスルー戦略:  
データがデータベースに書き込まれると常にデータを追加するか、キャッシュのデータを更新する
  
- TTLの追加
有効期限値(TTL)を設定することで一定期間でデータ項目を失効させることができる。遅延読み取りはデータが古くなる可能性があるが、空ノードによる障害は発生しない。書き込みスルーでは常に新しいデータとなるが、空ノードによる障害が発生して、過剰なデータがキャッシュに入力されることがある。各書き込みに有効期限値を追加することで、核戦略の利点を得ることができると同時に余分なデータでキャッシュが乱雑になることを回避できる。  
  
[キャッシュ戦略](https://docs.aws.amazon.com/ja_jp/AmazonElastiCache/latest/mem-ug/Strategies.html)
  
### ElasticCache for Redis　Redis AUTH
Redis AUTHコマンドを使用して、パスワードで保護されたRedisサーバー上のRedisコマンドの実行権限をユーザーに付与する前に、パスワードの入力を求めることでデータのセキュリティを強化できる。
  
  
### SQS拡張クライアントライブラリ  
Amazon S3およびJava用Amazon SQS拡張クライアントライブラリを使用することで、SQSキューに送信されるメッセージサイズの制限を超える大きなサイズのメッセージを許可することができる。キューに格納できる1メッセージあたりのサイズは最大256KBだが、拡張クライアントライブラリを利用することで最大2GBまで保存および処理することが可能となる。アプリケーションでキューを連続して作成して非アクティブな状態のままにするか、大量のデータをキューに保存する必要がない限り、データの保存にS3を使用することが推奨されている。
  
Java用Amazon SQS拡張クライアントライブラリは以下の対応が可能
- メッセージを常にS3に保存するか、メッセージのサイズが256KBを超える場合のみ保存するかを指定する  
  
- S3バケットに保存されている単一のメッセージオブジェクトを参照するメッセージを送信する
  
- S3バケットから該当するメッセージオブジェクトを取得・削除する  
[Amazon SQS](https://qiita.com/leomaro7/items/296c46ad6366a8dca28c)
  
  
   

